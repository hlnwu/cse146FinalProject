{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protected Attributes vs Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project was inspired by ProPublica's analysis on COMPAS, a software utilized by the legal system to help determine an individual's chance of recidivating. One crucial problem identified by ProPublica through their investigation was the racial bias of the results. According to the published web page on their findings, ProPublica states: \"Race was also quite predictive of a higher score. While Black defendants had higher recidivism rates overall, when adjusted for this difference and other factors, they were 45 percent more likely to get a higher score than whites.\"\n",
    "\n",
    "In our project, we looked at whether race affected precision and accuracy by including and excluding the race feature.\n",
    "\n",
    "reference: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set: https://data.iowa.gov/Correctional-System/3-Year-Recidivism-for-Offenders-Released-from-Pris/mw8r-vqy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set into a pandas data frame\n",
    "iowa_df = pd.read_csv(\"3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv\")\n",
    "\n",
    "# iowa_df.head(5) # Show the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# printing out unique values of a column\n",
    "# iowa_df['Race - Ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop values that are incomplete\n",
    "drop_row_list = ['White -', 'Black -', 'N/A -', np.nan]\n",
    "\n",
    "iowa_clean_df = iowa_df[~iowa_df['Race - Ethnicity'].isin(drop_row_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the data frames that includes the features and labels\n",
    "features_list = ['Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population']\n",
    "\n",
    "features_df = iowa_clean_df[features_list]\n",
    "\n",
    "labels_df = iowa_clean_df[['Return to Prison']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "### Ethnicity and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gets the ethnicity count and the gender count within each ethnicity group\n",
    "ethnic_gender_series = iowa_clean_df.groupby(['Race - Ethnicity', 'Sex']).count().ix[:, 0]\n",
    "ethnic_gender_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separating list out by male and female to create stacked bar plot\n",
    "female_count_list = []\n",
    "male_count_list = []\n",
    "for i in range(ethnic_gender_series.size):\n",
    "    idx = i\n",
    "    if (idx) % 2 == 0:\n",
    "        male_count_list.append(ethnic_gender_series[idx])\n",
    "    else:\n",
    "        female_count_list.append(ethnic_gender_series[idx])\n",
    "\n",
    "# hard-coded in 0 for Asian... - Hispanic\n",
    "female_count_list.insert(2, 0)\n",
    "\n",
    "print(male_count_list)\n",
    "print(female_count_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference for label: https://python-graph-gallery.com/10-barplot-with-number-of-observation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the stacked bar plot\n",
    "width = 0.5\n",
    "ind = np.arange(8) \n",
    "\n",
    "p1 = plt.bar(ind, male_count_list, width)\n",
    "p2 = plt.bar(ind, female_count_list, width, bottom=male_count_list)\n",
    "\n",
    "ethnic_list = ['American Indian or Alaska Native - Hispanic', \\\n",
    "               'American Indian or Alaska Native - Non-Hispanic', \\\n",
    "               'Asian or Pacific Islander - Hispanic', \\\n",
    "               'Asian or Pacific Islander - Non-Hispanic', \\\n",
    "               'Black - Hispanic', \\\n",
    "               'Black - Non-Hispanic', \\\n",
    "               'White - Hispanic', \\\n",
    "               'White - Non-Hispanic']\n",
    "\n",
    "# creates labels\n",
    "total_count_list = []\n",
    "for i in range(8):\n",
    "    total_count = female_count_list[i] + male_count_list[i]\n",
    "    total_count_list.append(total_count)\n",
    "    \n",
    "# text on the top of each barplot\n",
    "for i in range(8):\n",
    "    plt.text(x = ind[i] - 0.3, y = total_count_list[i] + 1000, s = total_count_list[i], size = 10)\n",
    "\n",
    "plt.title('Count by Ethnicity and Gender')\n",
    "plt.ylabel('Number of Convicted')\n",
    "plt.xticks(ind, ethnic_list, rotation=90)\n",
    "plt.ylim([0, 20000])\n",
    "plt.yticks(np.arange(0, 20000, 2000))\n",
    "plt.legend((p1[0], p2[0]), ('Male', 'Female'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recidivism Count for Each Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gets the ethnicity count and the gender count within each ethnicity group\n",
    "ethnic_recidivism_series = iowa_clean_df.groupby(['Race - Ethnicity', 'Return to Prison']).count().ix[:, 0]\n",
    "ethnic_recidivism_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating list out by whether or not the individual recidivated within the last 3 years to create stacked bar plot\n",
    "yes_count_list = []\n",
    "no_count_list = []\n",
    "for i in range(ethnic_recidivism_series.size):\n",
    "    idx = i\n",
    "    if (idx) % 2 == 0:\n",
    "        no_count_list.append(ethnic_recidivism_series[idx])\n",
    "    else:\n",
    "        yes_count_list.append(ethnic_recidivism_series[idx])\n",
    "\n",
    "print(yes_count_list)\n",
    "print(no_count_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://matplotlib.org/examples/api/barchart_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.4\n",
    "yes_bar = plt.bar(ind, yes_count_list, width, color='red')\n",
    "\n",
    "women_means = (25, 32, 34, 20, 25)\n",
    "women_std = (3, 5, 2, 3, 3)\n",
    "no_bar = plt.bar(ind + width, no_count_list, width, color='orange')\n",
    "\n",
    "# creates labels\n",
    "yes_no_count_list = []\n",
    "for i in range(8):\n",
    "    yes_no_count_list.append(yes_count_list[i])\n",
    "    yes_no_count_list.append(no_count_list[i])\n",
    "    \n",
    "# adds the labels to the graph\n",
    "for i in range(8):\n",
    "    plt.text(x = ind[i] - 0.3, y = yes_no_count_list[2 * i] + 1000, s = yes_no_count_list[2 * i], size = 10)\n",
    "    plt.text(x = ind[i] + 0.2, y = yes_no_count_list[2 * i + 1] + 1000, s = yes_no_count_list[2 * i + 1], size = 10)\n",
    "\n",
    "plt.title('Count by Ethnicity and Recidivism')\n",
    "plt.ylabel('Recidivism Count')\n",
    "plt.xticks(ind, ethnic_list, rotation=90)\n",
    "plt.ylim([0, 15000])\n",
    "plt.yticks(np.arange(0, 12000, 2000))\n",
    "plt.legend((yes_bar[0], no_bar[0]), ('Yes', 'No'), loc=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Reference:\n",
    "Guides to how to write your own neural network:<br>\n",
    "https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6 <br>\n",
    "https://towardsdatascience.com/inroduction-to-neural-networks-in-python-7e0b422e6c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights    = np.random.rand(self.input.shape[1], 1)\n",
    "        self.y          = y\n",
    "        \n",
    "    # activation function ==> S(x) = 1/1+e^(-x)\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        if deriv == True:\n",
    "            return x * (1 - x)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # calculating predicted value y_hat\n",
    "    def feedforward(self):\n",
    "        self.layer1 = self.sigmoid(np.dot(self.input, self.weights))\n",
    "        \n",
    "    # used to propogate errors back and update weights\n",
    "    def backpropagation(self):\n",
    "        error = self.y - self.layer1\n",
    "        delta = error * self.sigmoid(self.layer1, deriv=True)\n",
    "        self.weights += np.dot(self.input.T, delta)\n",
    "\n",
    "    # train the neural net for 250 iterations\n",
    "    def train(self, epochs=250):\n",
    "        for epoch in range(epochs):\n",
    "            # flow forward and produce an output\n",
    "            self.feedforward()\n",
    "            # go back though the network to make corrections based on the output\n",
    "            self.backpropagation()    \n",
    "\n",
    "    # function to predict output on new and unseen input data                               \n",
    "    def predict(self, new_input):\n",
    "        prediction = self.sigmoid(np.dot(new_input, self.weights))\n",
    "        count = 0\n",
    "        list1 = []\n",
    "        for pred in prediction:\n",
    "            if pred[0] == 0.:\n",
    "                count += 1\n",
    "            if pred[0] not in list1:\n",
    "                list1.append(pred[0])\n",
    "        print(count, len(prediction))\n",
    "        return prediction, list1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features_matrix = features_df\n",
    "labels_matrix = labels_df\n",
    "\n",
    "# creating the binarized label for each unique value\n",
    "enc = preprocessing.LabelBinarizer()\n",
    "categorical_feature_mask = features_matrix.dtypes==object\n",
    "categorical_cols = features_matrix.columns[categorical_feature_mask].tolist()\n",
    "features_matrix = features_matrix.replace(np.nan, -1)\n",
    "\n",
    "for entry in categorical_cols:\n",
    "    features_matrix.reset_index(drop=True, inplace=True)\n",
    "    enc.fit(features_matrix[entry].astype(str))\n",
    "    transformed = enc.transform(features_matrix[entry].astype(str))\n",
    "    df = pd.DataFrame(transformed)\n",
    "    print(df)\n",
    "    features_matrix = pd.concat([features_matrix, df], axis=1).drop([entry], axis=1)\n",
    "\n",
    "# encode labels_df strings\n",
    "labels_matrix.replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# split data into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_matrix, labels_matrix, test_size=0.2, random_state=1)\n",
    "\n",
    "features_matrix\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# create neural network   \n",
    "NN = NeuralNetwork(x_train, y_train)\n",
    "\n",
    "# train neural network\n",
    "NN.train(20)\n",
    "\n",
    "recidivism_pred, list1 = NN.predict(x_test)\n",
    "print(list1)\n",
    "\n",
    "recidivism_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "### Creating the Model without Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing objects to integers\n",
    "enc = preprocessing.LabelBinarizer()\n",
    "copy = features_df\n",
    "categorical_feature_mask = copy.dtypes==object\n",
    "categorical_cols = copy.columns[categorical_feature_mask].tolist()\n",
    "copy = copy.replace(np.nan, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data frame with binarized values\n",
    "for entry in categorical_cols:\n",
    "    copy.reset_index(drop=True, inplace=True)\n",
    "    enc.fit(copy[entry].astype(str))\n",
    "    transformed = enc.transform(copy[entry].astype(str))\n",
    "    df = pd.DataFrame(transformed)\n",
    "    copy = pd.concat([copy, df], axis=1).drop([entry], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(copy, labels_df, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a graph to show which depth is the best\n",
    "index = -1\n",
    "max = -1\n",
    "for i in range(1,25):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_hat = dt.predict(x_test)\n",
    "    if (metrics.accuracy_score(y_test, y_hat) > max):\n",
    "        max = metrics.accuracy_score(y_test, y_hat)\n",
    "        index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the best depth to to create the decision tree classifier\n",
    "dt = tree.DecisionTreeClassifier(max_depth=index)\n",
    "dt.fit(x_train, y_train)\n",
    "y_hat = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Decision Tree: Recidivism Predictions Without Race ---\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_hat, average=None, zero_division=1))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_hat, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.unique(y_hat)\n",
    "values = [0,0]\n",
    "for entry in y_hat:\n",
    "    for i in range(arr.size):\n",
    "        if entry == arr[i]:\n",
    "            values[i] += 1\n",
    "\n",
    "print(arr)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.unique(y_test)\n",
    "values2 = [0,0]\n",
    "for entry in y_test.values:\n",
    "    for i in range(arr2.size):\n",
    "        if entry == arr2[i]:\n",
    "            values2[i] += 1\n",
    "            \n",
    "print(arr2)\n",
    "print(values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphing prediction vs actual recidivism count\n",
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values2, width)\n",
    "plt.title('Actual')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr2, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model with Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list3 = ['Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population', 'Race - Ethnicity']\n",
    "features_df3 = iowa_clean_df[features_list3]\n",
    "enc3 = preprocessing.LabelBinarizer()\n",
    "copy3 = features_df3\n",
    "\n",
    "categorical_feature_mask = copy3.dtypes==object\n",
    "categorical_cols = copy3.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "print(copy3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in categorical_cols:\n",
    "    copy3.reset_index(drop=True, inplace=True)\n",
    "    enc3.fit(copy3[entry].astype(str))\n",
    "    transformed = enc3.transform(copy3[entry].astype(str))\n",
    "    df = pd.DataFrame(transformed)\n",
    "    copy3 = pd.concat([copy3, df], axis=1).drop([entry], axis=1)\n",
    "    \n",
    "print(copy3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(copy3, labels_df, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1\n",
    "max = -1\n",
    "for i in range(1,25):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_hat = dt.predict(x_test)\n",
    "    if (metrics.accuracy_score(y_test, y_hat) > max):\n",
    "        max = metrics.accuracy_score(y_test, y_hat)\n",
    "        index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(max_depth=index)\n",
    "dt.fit(x_train, y_train)\n",
    "y_hat = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Decision Tree: Recidivism Predictions With Race ---\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_hat, average=None, zero_division=1))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_hat, average=None))\n",
    "\n",
    "arr = np.unique(y_hat)\n",
    "values = [0,0]\n",
    "for entry in y_hat:\n",
    "    for i in range(arr.size):\n",
    "        if entry == arr[i]:\n",
    "            values[i] += 1\n",
    "print(arr)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.unique(y_test)\n",
    "values2 = [0,0]\n",
    "for entry in y_test.values:\n",
    "    for i in range(arr2.size):\n",
    "        if entry == arr2[i]:\n",
    "            values2[i] += 1\n",
    "    \n",
    "print(arr2)\n",
    "print(values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values2, width)\n",
    "plt.title('Actual')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr2, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list2 = ['Return to Prison', 'New Offense Classification','New Offense Type', 'New Offense Sub Type', 'Recidivism Type', 'Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population']\n",
    "features_df2 = iowa_clean_df[features_list2]\n",
    "labels_df2 = iowa_clean_df[['Race - Ethnicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc2 = preprocessing.LabelBinarizer()\n",
    "copy2 = features_df2\n",
    "categorical_feature_mask = copy2.dtypes==object\n",
    "categorical_cols = copy2.columns[categorical_feature_mask].tolist()\n",
    "copy2 = copy2.replace(np.nan, -1)\n",
    "\n",
    "print(copy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in categorical_cols:\n",
    "    copy2.reset_index(drop=True, inplace=True)\n",
    "    enc2.fit(copy2[entry].astype(str))\n",
    "    transformed = enc2.transform(copy2[entry].astype(str))\n",
    "    df = pd.DataFrame(transformed)\n",
    "    copy2 = pd.concat([copy2, df], axis=1).drop([entry], axis=1)\n",
    "    \n",
    "print(copy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(copy2, labels_df2, test_size=0.2, random_state= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1;\n",
    "max = -1;\n",
    "err2 = [];\n",
    "x_example = np.array(range(1,25));\n",
    "for i in range(1,25):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_hat = dt.predict(x_test)\n",
    "    err2.append(1 - metrics.accuracy_score(y_test, y_hat));\n",
    "    if (metrics.accuracy_score(y_test, y_hat) > max):\n",
    "        max = metrics.accuracy_score(y_test, y_hat)\n",
    "        index = i\n",
    "\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = 'Max Depth'\n",
    "y_label = 'Test Error'\n",
    "plt.title('Depth vs Generalization Error')\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "\n",
    "plt.plot(x_example, err2, color='blue', label='x_train');\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(max_depth=index)\n",
    "dt.fit(x_train, y_train)\n",
    "y_hat = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Decision Tree: Race Predictions---\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_hat, average=None))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_hat, average=None))\n",
    "print(\"CM: \", metrics.confusion_matrix(y_test, y_hat, labels=ethnic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.unique(y_hat)\n",
    "values = [0,0,0,0]\n",
    "for entry in y_hat:\n",
    "    for i in range(arr.size):\n",
    "        if entry == arr[i]:\n",
    "            values[i] += 1\n",
    "            \n",
    "print(arr)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.unique(y_test)\n",
    "values2 = [0,0,0,0,0,0,0,0]\n",
    "for entry in y_test.values:\n",
    "    for i in range(arr2.size):\n",
    "        if entry == arr2[i]:\n",
    "            values2[i] += 1\n",
    "            \n",
    "print(arr2)\n",
    "print(values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clears graph to be reused\n",
    "plt.clf()\n",
    "\n",
    "width = 0.5\n",
    "ind = np.arange(len(values)) \n",
    "p1 = plt.bar(ind, values, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "ind = np.arange(8) \n",
    "p1 = plt.bar(ind, values2, width)\n",
    "plt.title('Actual')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr2, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "### Creating a Model Predicting Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_hat):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    for i in range(len(y)):\n",
    "        if y_hat[i] == 1 and y[i] == y_hat[i]:\n",
    "            true_positive += 1\n",
    "        elif y_hat[i] == 1 and y[i] != y_hat[i]:\n",
    "            false_positive += 1\n",
    "    if (true_positive + false_positive) == 0:\n",
    "        return 0\n",
    "    return true_positive / (true_positive + false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding strings\n",
    "race_dict = {'White - Non-Hispanic': 0,\n",
    "             'White - Hispanic': 1,\n",
    "             'Black - Non-Hispanic': 2,\n",
    "             'American Indian or Alaska Native - Non-Hispanic': 3,\n",
    "             'Black - Hispanic': 4,\n",
    "             'Asian or Pacific Islander - Non-Hispanic': 5,\n",
    "             'American Indian or Alaska Native - Hispanic': 6,\n",
    "             'Asian or Pacific Islander - Hispanic': 7\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_float = y_train.replace(race_dict)\n",
    "y_train_float = y_train_float.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rF = ensemble.RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "rF.fit(x_train.values, y_train_float.ravel())\n",
    "predictionRF = rF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display accuracy\n",
    "y_test_ravel = y_train_float.ravel()\n",
    "count = 0\n",
    "for i in range(len(predictionRF)):\n",
    "    if predictionRF[i] == y_test_ravel[i]:\n",
    "        count += 1\n",
    "        \n",
    "print(count / len(predictionRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_float = y_test.replace(race_dict)\n",
    "y_test_float = y_test_float.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_int = precision(y_test_float, predictionRF)\n",
    "print(precision_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.precision_score(y_test_float, predictionRF, average=None, zero_division=1)\n",
    "print(metrics.classification_report(y_test_float, predictionRF,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Creating a Model without Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all dtypes to \"category\"\n",
    "features_df[\"Release Type\"] = features_df[\"Release Type\"].astype(\"category\")\n",
    "features_df[\"Age At Release \"] = features_df[\"Age At Release \"].astype(\"category\")\n",
    "features_df[\"Offense Classification\"] = features_df[\"Offense Classification\"].astype(\"category\")\n",
    "features_df[\"Offense Type\"] = features_df[\"Offense Type\"].astype(\"category\")\n",
    "features_df[\"Target Population\"] = features_df[\"Target Population\"].astype(\"category\")\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding strings\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "features_df[\"Release Type\"] = features_df[\"Release Type\"].cat.codes\n",
    "features_df['Age At Release '] = features_df['Age At Release '].cat.codes\n",
    "features_df[\"Offense Classification\"] = features_df[\"Offense Classification\"].cat.codes\n",
    "features_df[\"Offense Type\"] = features_df[\"Offense Type\"].cat.codes\n",
    "features_df[\"Target Population\"] = features_df[\"Target Population\"].cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(labels_df[\"Return to Prison\"])\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features_df, labels_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "list1 = y_test.index.tolist()\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_hat_with_race = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(y_hat)):\n",
    "    if(y_hat[i]==1):\n",
    "        count+=1\n",
    "\n",
    "print(logisticRegr.score(x_test, y_test))\n",
    "print(logisticRegr.coef_)\n",
    "print(metrics.precision_score(y_test, y_hat_with_race, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_hat_with_race))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model without Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list3 = ['Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population', 'Race - Ethnicity']\n",
    "features_df3 = iowa_clean_df[features_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all dtypes to \"category\"\n",
    "features_df3[\"Release Type\"] = features_df3[\"Release Type\"].astype(\"category\")\n",
    "features_df3[\"Age At Release \"] = features_df3[\"Age At Release \"].astype(\"category\")\n",
    "features_df3[\"Offense Classification\"] = features_df3[\"Offense Classification\"].astype(\"category\")\n",
    "features_df3[\"Offense Type\"] = features_df3[\"Offense Type\"].astype(\"category\")\n",
    "features_df3[\"Target Population\"] = features_df3[\"Target Population\"].astype(\"category\")\n",
    "features_df3['Race - Ethnicity'] = features_df3['Race - Ethnicity'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding strings\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].astype(\"category\")\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "features_df3[\"Release Type\"] = features_df3[\"Release Type\"].cat.codes\n",
    "features_df3['Age At Release '] = features_df3['Age At Release '].cat.codes\n",
    "features_df3[\"Offense Classification\"] = features_df3[\"Offense Classification\"].cat.codes\n",
    "features_df3[\"Offense Type\"] = features_df3[\"Offense Type\"].cat.codes\n",
    "features_df3[\"Target Population\"] = features_df3[\"Target Population\"].cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(labels_df[\"Return to Prison\"])\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].cat.codes\n",
    "features_df3['Race - Ethnicity'] = features_df3['Race - Ethnicity'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(features_df3, labels_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "logisticRegr1 = LogisticRegression()\n",
    "logisticRegr1.fit(x1_train, y1_train)\n",
    "y_hat_without_race = logisticRegr1.predict(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_test, y_hat_without_race, average=None))\n",
    "print(logisticRegr1.score(x1_test, y1_test))\n",
    "print(classification_report(y_test, y_hat_without_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts the number of 'yes'/'no' predictions\n",
    "def count_recidivism(y_hat):\n",
    "    no_count = 0\n",
    "    yes_count = 0\n",
    "    no_yes_count = []\n",
    "    \n",
    "    for i in range(len(y_hat)):\n",
    "        if y_hat[i] == 0:\n",
    "            no_count += 1\n",
    "        else:\n",
    "            yes_count += 1\n",
    "    \n",
    "    no_yes_count.append(no_count)\n",
    "    no_yes_count.append(yes_count)\n",
    "    \n",
    "    return no_yes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x-axis labels\n",
    "arr = ['No', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following creates a graph where race is included as a feature\n",
    "values1 = count_recidivism(y_hat_with_race)\n",
    "\n",
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values1, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(values1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following creates a graph where race is not included as a feature\n",
    "values2 = count_recidivism(y_hat_without_race)\n",
    "\n",
    "width = 0.5\n",
    "ind = np.arange(2) \n",
    "p1 = plt.bar(ind, values2, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(values2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
