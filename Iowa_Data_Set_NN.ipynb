{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set: https://data.iowa.gov/Correctional-System/3-Year-Recidivism-for-Offenders-Released-from-Pris/mw8r-vqy4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data set into a pandas data frame\n",
    "iowa_df = pd.read_csv(\"3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv\")\n",
    "\n",
    "# iowa_df.head(5) # Show the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# printing out unique values of a column\n",
    "# iowa_df['Race - Ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_row_list = ['White -', 'Black -', 'N/A -']\n",
    "\n",
    "iowa_clean_df = iowa_df[~iowa_df['Race - Ethnicity'].isin(drop_row_list)]\n",
    "\n",
    "# iowa_na_df = iowa_clean_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features_list = ['Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population']\n",
    "\n",
    "features_df = iowa_clean_df[features_list]\n",
    "labels_df = iowa_clean_df[['Return to Prison']]\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity and Sex Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gets the ethnicity count and the gender count within each ethnicity group\n",
    "ethnic_gender_series = iowa_clean_df.groupby(['Race - Ethnicity', 'Sex']).count()['Fiscal Year Released']\n",
    "ethnic_gender_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating list out by male and female to create stacked bar plot\n",
    "female_count_list = []\n",
    "male_count_list = []\n",
    "for i in range(ethnic_gender_series.size):\n",
    "    idx = i\n",
    "    if (idx) % 2 == 0:\n",
    "        male_count_list.append(ethnic_gender_series[idx])\n",
    "    else:\n",
    "        female_count_list.append(ethnic_gender_series[idx])\n",
    "        \n",
    "print(male_count_list)\n",
    "print(female_count_list)\n",
    "\n",
    "female_count_list.insert(2, 0)\n",
    "print(female_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the stacked bar plot\n",
    "width = 0.5\n",
    "ind = np.arange(8) \n",
    "\n",
    "p1 = plt.bar(ind, male_count_list, width)\n",
    "p2 = plt.bar(ind, female_count_list, width, bottom=male_count_list)\n",
    "\n",
    "ethnic_list = ['American Indian or Alaska Native - Hispanic', \\\n",
    "               'American Indian or Alaska Native - Non-Hispanic', \\\n",
    "               'Asian or Pacific Islander - Hispanic', \\\n",
    "               'Asian or Pacific Islander - Non-Hispanic', \\\n",
    "               'Black - Hispanic', \\\n",
    "               'Black - Non-Hispanic', \\\n",
    "               'White - Hispanic', \\\n",
    "               'White - Non-Hispanic']\n",
    "\n",
    "\n",
    "# ethnic_list = iowa_clean_df['Race - Ethnicity'].unique()\n",
    "\n",
    "plt.title('Count by Ethnicity and Gender')\n",
    "plt.ylabel('Number of Convicted')\n",
    "plt.xticks(ind, ethnic_list, rotation=90)\n",
    "plt.yticks(np.arange(0, 1000, 1000))\n",
    "plt.legend((p1[0], p2[0]), ('Male', 'Female'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count of recidivism in each ethnic group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data set on race\n",
    "- before train eliminate race column\n",
    "- proxy variables that predict for race\n",
    "- treat race as independent variable\n",
    "  - predict race\n",
    "- blindness != feature is gone\n",
    "\n",
    "protected attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network reference:\n",
    "https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6 <br>\n",
    "https://towardsdatascience.com/inroduction-to-neural-networks-in-python-7e0b422e6c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights    = np.random.rand(self.input.shape[1], 1)\n",
    "        self.y          = y\n",
    "        \n",
    "    # activation function ==> S(x) = 1/1+e^(-x)\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        if deriv == True:\n",
    "            return x * (1 - x)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # calculating predicted value y_hat\n",
    "    def feedforward(self):\n",
    "        self.layer1 = self.sigmoid(np.dot(self.input, self.weights))\n",
    "        \n",
    "    # used to propogate errors back and update weights\n",
    "    def backpropagation(self):\n",
    "        error = self.y - self.layer1\n",
    "        delta = error * self.sigmoid(self.layer1, deriv=True)\n",
    "        self.weights += np.dot(self.input.T, delta)\n",
    "\n",
    "    # train the neural net for 250 iterations\n",
    "    def train(self, epochs=250):\n",
    "        for epoch in range(epochs):\n",
    "            # flow forward and produce an output\n",
    "            self.feedforward()\n",
    "            # go back though the network to make corrections based on the output\n",
    "            self.backpropagation()    \n",
    "\n",
    "    # function to predict output on new and unseen input data                               \n",
    "    def predict(self, new_input):\n",
    "        prediction = self.sigmoid(np.dot(new_input, self.weights))\n",
    "        count = 0\n",
    "        list1=[]\n",
    "        for pred in prediction:\n",
    "            if pred[0] == 0.:\n",
    "                count += 1\n",
    "            if pred[0] not in list1:\n",
    "                list1.append(pred[0])\n",
    "        print(count, len(prediction))\n",
    "        return prediction, list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features_matrix = features_df\n",
    "labels_matrix = labels_df\n",
    "\n",
    "# creating the binarized label for each unique value\n",
    "enc = preprocessing.LabelBinarizer()\n",
    "categorical_feature_mask = features_matrix.dtypes==object\n",
    "categorical_cols = features_matrix.columns[categorical_feature_mask].tolist()\n",
    "features_matrix = features_matrix.replace(np.nan, -1)\n",
    "\n",
    "for entry in categorical_cols:\n",
    "    features_matrix.reset_index(drop=True, inplace=True)\n",
    "    enc.fit(features_matrix[entry].astype(str))\n",
    "    transformed = enc.transform(features_matrix[entry].astype(str))\n",
    "    df = pd.DataFrame(transformed)\n",
    "    print(df)\n",
    "    features_matrix = pd.concat([features_matrix, df], axis=1).drop([entry], axis=1)\n",
    "\n",
    "# encode labels_df strings\n",
    "# labels_matrix.replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# split data into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_matrix, labels_matrix, test_size=0.2, random_state=1)\n",
    "# features_matrix\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neural network   \n",
    "NN = NeuralNetwork(x_train, y_train)\n",
    "# print(x_train, y_train)\n",
    "# y_train.head(20)\n",
    "# train neural network\n",
    "# NN.train(20)\n",
    "\n",
    "recidivism_pred, list1 = NN.predict(x_test)\n",
    "print(list1)\n",
    "\n",
    "recidivism_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references: https://towardsdatascience.com/encoding-categorical-features-21a2651a065c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "enc = preprocessing.LabelBinarizer()\n",
    "copy = features_df\n",
    "categorical_feature_mask = copy.dtypes==object\n",
    "categorical_cols = copy.columns[categorical_feature_mask].tolist()\n",
    "copy = copy.replace(np.nan, -1)\n",
    "# copy = copy.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "\n",
    "for entry in categorical_cols:\n",
    "    copy.reset_index(drop=True, inplace=True)\n",
    "    enc.fit(copy[entry].astype(str))\n",
    "    transformed = enc.transform(copy[entry].astype(str))\n",
    "#     print(transformed.shape, copy.shape, \"Unqiues:\", copy[entry].unique() )\n",
    "    df = pd.DataFrame(transformed)\n",
    "    copy = pd.concat([copy, df], axis=1).drop([entry], axis=1)\n",
    "#     print(\"New size:\",copy.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(copy, labels_df, test_size=0.2, random_state=3)\n",
    "index = -1;\n",
    "max = -1;\n",
    "for i in range(1,25):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_hat = dt.predict(x_test)\n",
    "    if (metrics.accuracy_score(y_test, y_hat) > max):\n",
    "        max = metrics.accuracy_score(y_test, y_hat)\n",
    "        index = i\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth=index)\n",
    "dt.fit(x_train, y_train)\n",
    "y_hat = dt.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_hat, average=None))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_hat, average=None))\n",
    "print(\"CM: \", metrics.confusion_matrix(y_test, y_hat, labels=ethnic_list))\n",
    "\n",
    "plt.clf()\n",
    "arr = np.unique(y_hat)\n",
    "values = [0,0,0,0,0,0,0,0]\n",
    "for entry in y_hat:\n",
    "    for i in range(arr.size):\n",
    "        if entry == arr[i]:\n",
    "            values[i] += 1\n",
    "print(arr, values)\n",
    "width = 0.5\n",
    "ind = np.arange(8) \n",
    "p1 = plt.bar(ind, values, width)\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "arr2 = np.unique(y_test)\n",
    "print(arr2)\n",
    "values2 = [0,0,0,0,0,0,0,0]\n",
    "for entry in y_test.values:\n",
    "#     print(entry)\n",
    "    for i in range(arr2.size):\n",
    "        if entry == arr2[i]:\n",
    "            values2[i] += 1\n",
    "print(arr2, values2)\n",
    "\n",
    "width = 0.5\n",
    "ind = np.arange(8) \n",
    "p1 = plt.bar(ind, values2, width)\n",
    "plt.title('Actual')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, arr2, rotation=90)\n",
    "plt.yticks(np.arange(0, 5500, 500))\n",
    "\n",
    "copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(features_df.columns)\n",
    "print(type(features_df))\n",
    "features_df[\"Release Type\"]=features_df[\"Release Type\"].astype(\"category\")\n",
    "features_df[\"Age At Release \"]=features_df[\"Age At Release \"].astype(\"category\")\n",
    "features_df[\"Offense Classification\"]=features_df[\"Offense Classification\"].astype(\"category\")\n",
    "features_df[\"Offense Type\"]=features_df[\"Offense Type\"].astype(\"category\")\n",
    "features_df[\"Target Population\"]=features_df[\"Target Population\"].astype(\"category\")\n",
    "labels_df[\"Return to Prison\"]=labels_df[\"Return to Prison\"].astype(\"category\")\n",
    "le = preprocessing.LabelEncoder()\n",
    "features_df[\"Release Type\"] = features_df[\"Release Type\"].cat.codes\n",
    "features_df['Age At Release '] = features_df['Age At Release '].cat.codes\n",
    "features_df[\"Offense Classification\"] = features_df[\"Offense Classification\"].cat.codes\n",
    "features_df[\"Offense Type\"] = features_df[\"Offense Type\"].cat.codes\n",
    "features_df[\"Target Population\"] = features_df[\"Target Population\"].cat.codes \n",
    "le.fit(labels_df[\"Return to Prison\"])\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].cat.codes\n",
    "print(labels_df)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_df, labels_df, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x)\n",
    "print(\"done\")\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_hat=logisticRegr.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_hat)):\n",
    "    if(y_hat[i]==1):\n",
    "        count+=1\n",
    "print(count)\n",
    "print(logisticRegr.score(x_test,y_test))\n",
    "print(logisticRegr.coef_)\n",
    "print(metrics.precision_score(y_test, y_hat, average=None))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_hat))\n",
    "\n",
    "# and plot the result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "features_list3 = ['Release Type', 'Age At Release ', 'Offense Classification', 'Offense Type', 'Target Population', 'Race - Ethnicity']\n",
    "features_df3 = iowa_clean_df[features_list3]\n",
    "features_df3[\"Release Type\"]=features_df3[\"Release Type\"].astype(\"category\")\n",
    "features_df3[\"Age At Release \"]=features_df3[\"Age At Release \"].astype(\"category\")\n",
    "features_df3[\"Offense Classification\"]=features_df3[\"Offense Classification\"].astype(\"category\")\n",
    "features_df3[\"Offense Type\"]=features_df3[\"Offense Type\"].astype(\"category\")\n",
    "features_df3[\"Target Population\"]=features_df3[\"Target Population\"].astype(\"category\")\n",
    "features_df3['Race - Ethnicity'] = features_df3['Race - Ethnicity'].astype(\"category\")\n",
    "\n",
    "labels_df[\"Return to Prison\"]=labels_df[\"Return to Prison\"].astype(\"category\")\n",
    "le = preprocessing.LabelEncoder()\n",
    "features_df3[\"Release Type\"] = features_df3[\"Release Type\"].cat.codes\n",
    "features_df3['Age At Release '] = features_df3['Age At Release '].cat.codes\n",
    "features_df3[\"Offense Classification\"] = features_df3[\"Offense Classification\"].cat.codes\n",
    "features_df3[\"Offense Type\"] = features_df3[\"Offense Type\"].cat.codes\n",
    "features_df3[\"Target Population\"] = features_df3[\"Target Population\"].cat.codes \n",
    "le.fit(labels_df[\"Return to Prison\"])\n",
    "labels_df[\"Return to Prison\"] = labels_df[\"Return to Prison\"].cat.codes\n",
    "features_df3['Race - Ethnicity'] = features_df3['Race - Ethnicity'].cat.codes\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(features_df3, labels_df, test_size=0.25, random_state=0)\n",
    "logisticRegr1 = LogisticRegression()\n",
    "logisticRegr1.fit(x1_train, y1_train)\n",
    "y_hat = logisticRegr1.predict(x1_test)\n",
    "print(metrics.precision_score(y_test, y_hat, average=None))\n",
    "print(logisticRegr1.score(x1_test,y1_test))\n",
    "print(classification_report(y_test,y_hat))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
